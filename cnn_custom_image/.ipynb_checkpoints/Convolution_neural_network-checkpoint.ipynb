{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set : 196\n",
      "\n",
      "Number of test set : 50\n",
      "\n",
      "('Epoch:', '001', 'cost =', '2.33503')\n",
      "('Epoch:', '006', 'cost =', '1.96295')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "workspace = os.getcwd()\n",
    "load_data_path = workspace + \"/data.npz\"\n",
    "load = np.load(load_data_path)\n",
    "\n",
    "# load data\n",
    "train_image = load['trainimg']\n",
    "train_label = load['trainlabel']\n",
    "test_image = load['testimg']\n",
    "test_label = load['testlabel']\n",
    "number_train = train_image.shape[0]\n",
    "number_test = test_image.shape[0]\n",
    "number_label = train_label.shape[1]\n",
    "print('Number of train set : %s\\n'%number_train)\n",
    "print('Number of test set : %s\\n'%number_test)\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# dropout \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, [None, 128*128*3])\n",
    "X_img = tf.reshape(X, [-1, 128, 128, 3])   # img 128x128x3\n",
    "\n",
    "with tf.name_scope('y_'):\n",
    "    Y = tf.placeholder(tf.float32, [None, 5])\n",
    "\n",
    "# Layer_1 ImgIn shape=(?, 128, 128, 3)\n",
    "\n",
    "with tf.name_scope(\"conv_1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([3, 3, 3, 32], stddev=0.01))\n",
    "    #    Convolution     -> (?, 128, 128, 32)\n",
    "    #    Max_Pool     -> (?, 64, 64, 32)\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# Layer_2 ImgIn shape=(?, 64, 64, 32)\n",
    "with tf.name_scope(\"conv_2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "    #    Conv      ->(?, 64, 64, 64)\n",
    "    #    Pool      ->(?, 32, 32, 64)\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "# Layer_2 ImgIn shape=(?, 64, 64, 32)\n",
    "with tf.name_scope(\"conv_3\"):\n",
    "    W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "    #    Conv      ->(?, 64, 64, 64)\n",
    "    #    Pool      ->(?, 32, 32, 64)\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "# L3 ImgIn shape=(?, 32, 32, 64)\n",
    "with tf.name_scope(\"conv_4\"):\n",
    "    W4 = tf.Variable(tf.random_normal([3, 3, 128, 256], stddev=0.01))\n",
    "    #    Conv      ->(?, 32, 32, 128)\n",
    "    #    Pool      ->(?, 16, 16, 128)\n",
    "    #    Reshape   ->(?, 16 * 16 * 128) # Flatten them for FC\n",
    "    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    L4 = tf.nn.relu(L4)\n",
    "    L4 = tf.nn.max_pool(L4, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "    L4_flat = tf.reshape(L4, [-1, 256 * 8 * 8])\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "with tf.name_scope(\"fc_1\"):\n",
    "    W5 = tf.get_variable(\"W5\", shape=[256 * 8 * 8, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([625]))\n",
    "    L5 = tf.nn.relu(tf.matmul(L4_flat, W5) + b5)\n",
    "    L5 = tf.nn.dropout(L5, keep_prob=keep_prob)\n",
    "\n",
    "# L5 Final FC 625 inputs -> 5 outputs\n",
    "with tf.name_scope(\"output_layer\"):\n",
    "    W6 = tf.get_variable(\"W6\", shape=[625, 5],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b6 = tf.Variable(tf.random_normal([5]))\n",
    "    logits = tf.matmul(L5, W6) + b6\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))\n",
    "    cost_sum = tf.summary.scalar(\"cost\",cost)\n",
    "\n",
    "with tf.name_scope(\"Train\") as scope:    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "# tensorboard --logdir=./logs/xor_logs\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./board/cnn\")\n",
    "writer.add_graph(sess.graph)  # Show the graph\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train model\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(number_train / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        randidx = np.random.randint(number_train,size=batch_size)\n",
    "        batch_xs = train_image[randidx,:]\n",
    "        batch_ys = train_label[randidx,:]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    if epoch%5 == 0:\n",
    "        summary_str = sess.run(merged_summary,feed_dict = {X:batch_xs ,Y:batch_ys,keep_prob:1})\n",
    "        writer.add_summary(summary_str,epoch)\n",
    "        writer.flush()\n",
    "        print('Epoch:', '%03d' % (epoch + 1), 'cost =', '{:.5f}'.format(avg_cost))\n",
    "\n",
    "print('Finished')\n",
    "\n",
    "\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_image, Y: test_label, keep_prob: 1}))\n",
    "\n",
    "# predict\n",
    "\n",
    "print(\"Label: \", sess.run(tf.argmax(test_label[0:1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X:test_image[0:1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(test_image[0:1].\n",
    "           reshape(128,128,3), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
